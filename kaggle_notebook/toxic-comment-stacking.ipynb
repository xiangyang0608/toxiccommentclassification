{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7477375,"sourceType":"datasetVersion","datasetId":4281512}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-25T18:23:14.347617Z","iopub.execute_input":"2024-01-25T18:23:14.347887Z","iopub.status.idle":"2024-01-25T18:23:15.462296Z","shell.execute_reply.started":"2024-01-25T18:23:14.347862Z","shell.execute_reply":"2024-01-25T18:23:15.461338Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dl-kaggle-dataset/cleaned_train_x.csv\n/kaggle/input/dl-kaggle-dataset/cleaned_val_x.csv\n/kaggle/input/dl-kaggle-dataset/Train.py\n/kaggle/input/dl-kaggle-dataset/models_zoo.py\n/kaggle/input/dl-kaggle-dataset/cleaned_test_x.csv\n/kaggle/input/dl-kaggle-dataset/utility.py\n/kaggle/input/dl-kaggle-dataset/train_y.csv\n/kaggle/input/dl-kaggle-dataset/train_x.csv\n/kaggle/input/dl-kaggle-dataset/test_x.csv\n/kaggle/input/dl-kaggle-dataset/glove.840B.300d.txt\n/kaggle/input/dl-kaggle-dataset/DataPreprocessing.py\n/kaggle/input/dl-kaggle-dataset/val_x.csv\n/kaggle/input/dl-kaggle-dataset/val_y.csv\n/kaggle/input/dl-kaggle-dataset/rnn_baseline.py\n/kaggle/input/dl-kaggle-dataset/cleanwords.txt\n/kaggle/input/dl-kaggle-dataset/DataLoader.py\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n# import module we'll need to import our custom module\nfrom shutil import copyfile\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/DataLoader.py\", dst = \"../working/DataLoader.py\")\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/models_zoo.py\", dst = \"../working/models_zoo.py\")\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/Train.py\", dst = \"../working/Train.py\")\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/utility.py\", dst = \"../working/utility.py\")\n# import all our functions\nfrom DataLoader import DataLoader\nfrom Train import Trainer\nfrom utility import worst_group_accuracy\nfrom models_zoo import get_baseline, get_LSTM, get_LSTM_attn, get_GRU, get_gru_rnn_attention","metadata":{"execution":{"iopub.status.busy":"2024-01-25T18:24:41.166977Z","iopub.execute_input":"2024-01-25T18:24:41.167509Z","iopub.status.idle":"2024-01-25T18:24:57.517915Z","shell.execute_reply.started":"2024-01-25T18:24:41.167475Z","shell.execute_reply":"2024-01-25T18:24:57.517056Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom keras.preprocessing.text import Tokenizer\n\nglove_path = os.path.join(dirname, 'glove.840B.300d.txt')\nembedding_path = [glove_path]\nMAX_SEQUENCE_LENGTH = 350\nMAX_FEATURES = 100000\nEMBEDDING_DIM = 300\ntorch.manual_seed(0)\ndataloader = DataLoader()\nembedding_index = dataloader.load_embedding(embedding_path)\n\ntrain_x = pd.read_csv(os.path.join(dirname, 'cleaned_train_x.csv'))\nval_x = pd.read_csv(os.path.join(dirname, 'cleaned_val_x.csv'))\ntest_x = pd.read_csv(os.path.join(dirname, 'cleaned_test_x.csv'))\n\ntrain_y = pd.read_csv(os.path.join(dirname, 'train_y.csv'))\nval_y = pd.read_csv(os.path.join(dirname, 'val_y.csv'))\nlist_classes = ['y']\ntrain_y, val_y = dataloader.load_dataset(train_x, train_y, val_x, val_y, test_x, list_classes)\n\ntokenizer = Tokenizer(num_words = MAX_FEATURES)\ntrain_x, test_x, val_x, word_index = dataloader.tokenize(tokenizer, MAX_SEQUENCE_LENGTH)\nembedding_matrix = dataloader.create_embedding_matrix(word_index, EMBEDDING_DIM, embedding_index, MAX_FEATURES)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T18:25:15.654918Z","iopub.execute_input":"2024-01-25T18:25:15.656213Z","iopub.status.idle":"2024-01-25T18:29:12.479455Z","shell.execute_reply.started":"2024-01-25T18:25:15.656177Z","shell.execute_reply":"2024-01-25T18:29:12.478387Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Total 2195884 word vectors\nShape of train_y : (269038, 1)\nShape of val_y : (45180, 1)\nShape of train_x tensor: (269038, 350)\nShape of test_data tensor: (133782, 350)\nShape of val_data tensor: (45180, 350)\nFound 136016 unique tokens\nNull word embeddings: 21362\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_x.shape)\nprint(train_y.shape)\nprint(val_x.shape)\nprint(val_y.shape)\nprint(test_x.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T18:31:11.838037Z","iopub.execute_input":"2024-01-25T18:31:11.838950Z","iopub.status.idle":"2024-01-25T18:31:11.844123Z","shell.execute_reply.started":"2024-01-25T18:31:11.838915Z","shell.execute_reply":"2024-01-25T18:31:11.843162Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(269038, 350)\n(269038, 1)\n(45180, 350)\n(45180, 1)\n(133782, 350)\n","output_type":"stream"}]},{"cell_type":"code","source":"MODEL_CHECKPOINT_FOLDER = \"checkpoints/\"\nTEMPORARY_CHECKPOINTS_PATH = 'temporary_checkpoints/'\nnb_words = min(MAX_FEATURES, len(word_index))\ndef get_model():\n    return get_LSTM(nb_words, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, out_size=1)\n\ntrainer = Trainer(model_stamp='get_LSTM', epoch_num=4, learning_rate=1e-3)\nmodels,val_loss,total_auc,fold_predictions = trainer.train_folds(X=train_x, y=train_y, fold_count=4, batch_size=256, get_model_func=get_model)\nprint(\"Predicting val results...\")\nLSTM_val_predicts = []\nfor fold_id, model in enumerate(models):\n    val_predicts = model.predict(val_x, batch_size=256, verbose=1)\n    LSTM_val_predicts.append(val_predicts)\nval_y_test = pd.read_csv(os.path.join(dirname, 'val_y.csv'))\nfolds_WGA = []\nfor fold in LSTM_val_predicts:\n    pred_df = pd.DataFrame()\n    pred_df['pred'] = [val[-1] for val in fold]\n    pred_df = pred_df.reset_index()\n    metric = worst_group_accuracy(pred_df, val_y_test)\n    print(f'Fold_WGA: {metric}')\n    print('-------------------------------------')\n    folds_WGA.append(metric)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T12:45:49.506064Z","iopub.execute_input":"2024-01-25T12:45:49.506469Z","iopub.status.idle":"2024-01-25T13:13:10.524909Z","shell.execute_reply.started":"2024-01-25T12:45:49.506438Z","shell.execute_reply":"2024-01-25T13:13:10.524011Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding (Embedding)       (None, 350, 300)             3000000   ['input_1[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d (Spatial  (None, 350, 300)             0         ['embedding[0][0]']           \n Dropout1D)                                                                                       \n                                                                                                  \n bidirectional (Bidirection  (None, 350, 100)             140400    ['spatial_dropout1d[0][0]']   \n al)                                                                                              \n                                                                                                  \n dropout (Dropout)           (None, 350, 100)             0         ['bidirectional[0][0]']       \n                                                                                                  \n bidirectional_1 (Bidirecti  (None, 350, 100)             60400     ['dropout[0][0]']             \n onal)                                                                                            \n                                                                                                  \n dropout_1 (Dropout)         (None, 350, 100)             0         ['bidirectional_1[0][0]']     \n                                                                                                  \n global_average_pooling1d (  (None, 100)                  0         ['dropout_1[0][0]']           \n GlobalAveragePooling1D)                                                                          \n                                                                                                  \n global_max_pooling1d (Glob  (None, 100)                  0         ['dropout_1[0][0]']           \n alMaxPooling1D)                                                                                  \n                                                                                                  \n concatenate (Concatenate)   (None, 200)                  0         ['global_average_pooling1d[0][\n                                                                    0]',                          \n                                                                     'global_max_pooling1d[0][0]']\n                                                                                                  \n dense (Dense)               (None, 50)                   10050     ['concatenate[0][0]']         \n                                                                                                  \n dense_1 (Dense)             (None, 1)                    51        ['dense[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 30210901 (115.25 MB)\nTrainable params: 210901 (823.83 KB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 91s 105ms/step - loss: 0.2414 - accuracy: 0.9183 - val_loss: 0.3136 - val_accuracy: 0.7885\nEpoch 2/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.2042 - accuracy: 0.9201 - val_loss: 0.2528 - val_accuracy: 0.8983\nEpoch 3/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.1950 - accuracy: 0.9225 - val_loss: 0.2457 - val_accuracy: 0.8889\nEpoch 4/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.1896 - accuracy: 0.9237 - val_loss: 0.2294 - val_accuracy: 0.8994\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9697834996955871\nModel: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_1 (Embedding)     (None, 350, 300)             3000000   ['input_2[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_1 (Spati  (None, 350, 300)             0         ['embedding_1[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_2 (Bidirecti  (None, 350, 100)             140400    ['spatial_dropout1d_1[0][0]'] \n onal)                                                                                            \n                                                                                                  \n dropout_2 (Dropout)         (None, 350, 100)             0         ['bidirectional_2[0][0]']     \n                                                                                                  \n bidirectional_3 (Bidirecti  (None, 350, 100)             60400     ['dropout_2[0][0]']           \n onal)                                                                                            \n                                                                                                  \n dropout_3 (Dropout)         (None, 350, 100)             0         ['bidirectional_3[0][0]']     \n                                                                                                  \n global_average_pooling1d_1  (None, 100)                  0         ['dropout_3[0][0]']           \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n global_max_pooling1d_1 (Gl  (None, 100)                  0         ['dropout_3[0][0]']           \n obalMaxPooling1D)                                                                                \n                                                                                                  \n concatenate_1 (Concatenate  (None, 200)                  0         ['global_average_pooling1d_1[0\n )                                                                  ][0]',                        \n                                                                     'global_max_pooling1d_1[0][0]\n                                                                    ']                            \n                                                                                                  \n dense_2 (Dense)             (None, 50)                   10050     ['concatenate_1[0][0]']       \n                                                                                                  \n dense_3 (Dense)             (None, 1)                    51        ['dense_2[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 30210901 (115.25 MB)\nTrainable params: 210901 (823.83 KB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 93s 108ms/step - loss: 0.2579 - accuracy: 0.8964 - val_loss: 0.1717 - val_accuracy: 0.9333\nEpoch 2/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.2159 - accuracy: 0.9104 - val_loss: 0.1655 - val_accuracy: 0.9338\nEpoch 3/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.2055 - accuracy: 0.9148 - val_loss: 0.1591 - val_accuracy: 0.9353\nEpoch 4/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.1989 - accuracy: 0.9170 - val_loss: 0.1584 - val_accuracy: 0.9358\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9243973119864703\nModel: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_3 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_2 (Embedding)     (None, 350, 300)             3000000   ['input_3[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_2 (Spati  (None, 350, 300)             0         ['embedding_2[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_4 (Bidirecti  (None, 350, 100)             140400    ['spatial_dropout1d_2[0][0]'] \n onal)                                                                                            \n                                                                                                  \n dropout_4 (Dropout)         (None, 350, 100)             0         ['bidirectional_4[0][0]']     \n                                                                                                  \n bidirectional_5 (Bidirecti  (None, 350, 100)             60400     ['dropout_4[0][0]']           \n onal)                                                                                            \n                                                                                                  \n dropout_5 (Dropout)         (None, 350, 100)             0         ['bidirectional_5[0][0]']     \n                                                                                                  \n global_average_pooling1d_2  (None, 100)                  0         ['dropout_5[0][0]']           \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n global_max_pooling1d_2 (Gl  (None, 100)                  0         ['dropout_5[0][0]']           \n obalMaxPooling1D)                                                                                \n                                                                                                  \n concatenate_2 (Concatenate  (None, 200)                  0         ['global_average_pooling1d_2[0\n )                                                                  ][0]',                        \n                                                                     'global_max_pooling1d_2[0][0]\n                                                                    ']                            \n                                                                                                  \n dense_4 (Dense)             (None, 50)                   10050     ['concatenate_2[0][0]']       \n                                                                                                  \n dense_5 (Dense)             (None, 1)                    51        ['dense_4[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 30210901 (115.25 MB)\nTrainable params: 210901 (823.83 KB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 93s 109ms/step - loss: 0.2538 - accuracy: 0.8981 - val_loss: 0.2167 - val_accuracy: 0.9139\nEpoch 2/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.2082 - accuracy: 0.9137 - val_loss: 0.1825 - val_accuracy: 0.9270\nEpoch 3/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.1972 - accuracy: 0.9179 - val_loss: 0.1788 - val_accuracy: 0.9283\nEpoch 4/4\n789/789 [==============================] - 83s 106ms/step - loss: 0.1910 - accuracy: 0.9199 - val_loss: 0.1859 - val_accuracy: 0.9244\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9063268224588992\nModel: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_4 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_3 (Embedding)     (None, 350, 300)             3000000   ['input_4[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_3 (Spati  (None, 350, 300)             0         ['embedding_3[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_6 (Bidirecti  (None, 350, 100)             140400    ['spatial_dropout1d_3[0][0]'] \n onal)                                                                                            \n                                                                                                  \n dropout_6 (Dropout)         (None, 350, 100)             0         ['bidirectional_6[0][0]']     \n                                                                                                  \n bidirectional_7 (Bidirecti  (None, 350, 100)             60400     ['dropout_6[0][0]']           \n onal)                                                                                            \n                                                                                                  \n dropout_7 (Dropout)         (None, 350, 100)             0         ['bidirectional_7[0][0]']     \n                                                                                                  \n global_average_pooling1d_3  (None, 100)                  0         ['dropout_7[0][0]']           \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n global_max_pooling1d_3 (Gl  (None, 100)                  0         ['dropout_7[0][0]']           \n obalMaxPooling1D)                                                                                \n                                                                                                  \n concatenate_3 (Concatenate  (None, 200)                  0         ['global_average_pooling1d_3[0\n )                                                                  ][0]',                        \n                                                                     'global_max_pooling1d_3[0][0]\n                                                                    ']                            \n                                                                                                  \n dense_6 (Dense)             (None, 50)                   10050     ['concatenate_3[0][0]']       \n                                                                                                  \n dense_7 (Dense)             (None, 1)                    51        ['dense_6[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 30210901 (115.25 MB)\nTrainable params: 210901 (823.83 KB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 92s 108ms/step - loss: 0.2396 - accuracy: 0.9041 - val_loss: 0.2301 - val_accuracy: 0.9089\nEpoch 2/4\n789/789 [==============================] - 84s 106ms/step - loss: 0.1935 - accuracy: 0.9196 - val_loss: 0.2199 - val_accuracy: 0.9125\nEpoch 3/4\n789/789 [==============================] - 83s 106ms/step - loss: 0.1844 - accuracy: 0.9231 - val_loss: 0.2434 - val_accuracy: 0.9003\nEpoch 4/4\n789/789 [==============================] - 83s 106ms/step - loss: 0.1780 - accuracy: 0.9256 - val_loss: 0.2207 - val_accuracy: 0.9081\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.8845338390657546\nPredicting val results...\n177/177 [==============================] - 6s 36ms/step\n177/177 [==============================] - 6s 36ms/step\n177/177 [==============================] - 6s 36ms/step\n177/177 [==============================] - 6s 36ms/step\nmale_1: 0.8908709338929696\nfemale_1: 0.9039212357833984\nLGBTQ_1: 0.8009608785175018\nchristian_1: 0.929010989010989\nmuslim_1: 0.8104265402843602\nother_religions_1: 0.8651115618661258\nblack_1: 0.7596852300242131\nwhite_1: 0.7833972793861179\nFold_WGA: 0.7596852300242131\n-------------------------------------\nmale_1: 0.8931794333683106\nfemale_1: 0.9032422339161432\nLGBTQ_1: 0.8091969800960879\nchristian_1: 0.9312087912087912\nmuslim_1: 0.8246445497630331\nother_religions_1: 0.8661257606490872\nblack_1: 0.7766343825665859\nwhite_1: 0.793163585629578\nFold_WGA: 0.7766343825665859\n-------------------------------------\nmale_1: 0.8963273871983211\nfemale_1: 0.9046002376506536\nLGBTQ_1: 0.8098833218943033\nchristian_1: 0.9314285714285714\nmuslim_1: 0.8260663507109005\nother_religions_1: 0.8651115618661258\nblack_1: 0.7730024213075061\nwhite_1: 0.788280432507848\nFold_WGA: 0.7730024213075061\n-------------------------------------\nmale_1: 0.89800629590766\nfemale_1: 0.9059582413851638\nLGBTQ_1: 0.8002745367192862\nchristian_1: 0.929010989010989\nmuslim_1: 0.8251184834123223\nother_religions_1: 0.8691683569979716\nblack_1: 0.7723970944309927\nwhite_1: 0.7959539588419952\nFold_WGA: 0.7723970944309927\n-------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:14:15.649793Z","iopub.execute_input":"2024-01-25T13:14:15.650451Z","iopub.status.idle":"2024-01-25T13:14:15.659725Z","shell.execute_reply.started":"2024-01-25T13:14:15.650419Z","shell.execute_reply":"2024-01-25T13:14:15.658889Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#######################################\n### print out single model's performance\n### store train set predictions \n### store val set predictions\n### store test set predictions\n#######################################\nLSTM_score, LSTM_train_pred, LSTM_val_pred, LSTM_test_pred = save_single_model(models, val_x, test_x, fold_predictions, folds_WGA, 'LSTM')","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:18:06.578444Z","iopub.execute_input":"2024-01-25T13:18:06.579390Z","iopub.status.idle":"2024-01-25T13:19:50.581537Z","shell.execute_reply.started":"2024-01-25T13:18:06.579353Z","shell.execute_reply":"2024-01-25T13:19:50.580667Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"177/177 [==============================] - 6s 36ms/step\n523/523 [==============================] - 19s 36ms/step\n177/177 [==============================] - 6s 36ms/step\n523/523 [==============================] - 19s 36ms/step\n177/177 [==============================] - 6s 35ms/step\n523/523 [==============================] - 19s 35ms/step\n177/177 [==============================] - 6s 36ms/step\n523/523 [==============================] - 19s 36ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"LSTM_score","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:49:44.695260Z","iopub.execute_input":"2024-01-25T14:49:44.695620Z","iopub.status.idle":"2024-01-25T14:49:44.701446Z","shell.execute_reply.started":"2024-01-25T14:49:44.695591Z","shell.execute_reply":"2024-01-25T14:49:44.700485Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"[0.7596852300242131,\n 0.7766343825665859,\n 0.7730024213075061,\n 0.7723970944309927]"},"metadata":{}}]},{"cell_type":"code","source":"MODEL_CHECKPOINT_FOLDER = \"checkpoints/\"\nTEMPORARY_CHECKPOINTS_PATH = 'temporary_checkpoints/'\nnb_words = min(MAX_FEATURES, len(word_index))\ndef get_model():\n    return get_GRU(nb_words, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, out_size=1)\n\ntrainer = Trainer(model_stamp='gru', epoch_num=4, learning_rate=1e-3)\nmodels,val_loss,total_auc,fold_predictions = trainer.train_folds(X=train_x, y=train_y, fold_count=4, batch_size=256, get_model_func=get_model)\nprint(\"Predicting val results...\")\nLSTM_val_predicts = []\nfor fold_id, model in enumerate(models):\n    val_predicts = model.predict(val_x, batch_size=256, verbose=1)\n    LSTM_val_predicts.append(val_predicts)\nval_y_test = pd.read_csv(os.path.join(dirname, 'val_y.csv'))\nfolds_WGA = []\nfor fold in LSTM_val_predicts:\n    pred_df = pd.DataFrame()\n    pred_df['pred'] = [val[-1] for val in fold]\n    pred_df = pred_df.reset_index()\n    metric = worst_group_accuracy(pred_df, val_y_test)\n    print(f'Fold_WGA: {metric}')\n    folds_WGA.append(metric)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:20:47.884939Z","iopub.execute_input":"2024-01-25T13:20:47.885571Z","iopub.status.idle":"2024-01-25T13:48:37.591087Z","shell.execute_reply.started":"2024-01-25T13:20:47.885540Z","shell.execute_reply":"2024-01-25T13:48:37.590210Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_5 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_4 (Embedding)     (None, 350, 300)             3000000   ['input_5[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_4 (Spati  (None, 350, 300)             0         ['embedding_4[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_8 (Bidirecti  (None, 350, 120)             130320    ['spatial_dropout1d_4[0][0]'] \n onal)                                                                                            \n                                                                                                  \n bidirectional_9 (Bidirecti  (None, 350, 120)             65520     ['bidirectional_8[0][0]']     \n onal)                                                                                            \n                                                                                                  \n concatenate_4 (Concatenate  (None, 350, 240)             0         ['bidirectional_8[0][0]',     \n )                                                                   'bidirectional_9[0][0]']     \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_4[0][0]']       \n                                                                                                  \n global_max_pooling1d_4 (Gl  (None, 240)                  0         ['concatenate_4[0][0]']       \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_4  (None, 240)                  0         ['concatenate_4[0][0]']       \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n concatenate_5 (Concatenate  (None, 720)                  0         ['last[0][0]',                \n )                                                                   'global_max_pooling1d_4[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_4[0\n                                                                    ][0]']                        \n                                                                                                  \n dropout_8 (Dropout)         (None, 720)                  0         ['concatenate_5[0][0]']       \n                                                                                                  \n dense_8 (Dense)             (None, 144)                  103824    ['dropout_8[0][0]']           \n                                                                                                  \n dense_9 (Dense)             (None, 1)                    145       ['dense_8[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 30299809 (115.58 MB)\nTrainable params: 299809 (1.14 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 95s 113ms/step - loss: 0.2281 - accuracy: 0.9184 - val_loss: 0.2570 - val_accuracy: 0.8821\nEpoch 2/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.2018 - accuracy: 0.9209 - val_loss: 0.2314 - val_accuracy: 0.8964\nEpoch 3/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.1935 - accuracy: 0.9230 - val_loss: 0.2197 - val_accuracy: 0.9065\nEpoch 4/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.1876 - accuracy: 0.9241 - val_loss: 0.2234 - val_accuracy: 0.9039\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9689035400725988\nModel: \"model_5\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_6 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_5 (Embedding)     (None, 350, 300)             3000000   ['input_6[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_5 (Spati  (None, 350, 300)             0         ['embedding_5[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_10 (Bidirect  (None, 350, 120)             130320    ['spatial_dropout1d_5[0][0]'] \n ional)                                                                                           \n                                                                                                  \n bidirectional_11 (Bidirect  (None, 350, 120)             65520     ['bidirectional_10[0][0]']    \n ional)                                                                                           \n                                                                                                  \n concatenate_6 (Concatenate  (None, 350, 240)             0         ['bidirectional_10[0][0]',    \n )                                                                   'bidirectional_11[0][0]']    \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_6[0][0]']       \n                                                                                                  \n global_max_pooling1d_5 (Gl  (None, 240)                  0         ['concatenate_6[0][0]']       \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_5  (None, 240)                  0         ['concatenate_6[0][0]']       \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n concatenate_7 (Concatenate  (None, 720)                  0         ['last[0][0]',                \n )                                                                   'global_max_pooling1d_5[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_5[0\n                                                                    ][0]']                        \n                                                                                                  \n dropout_9 (Dropout)         (None, 720)                  0         ['concatenate_7[0][0]']       \n                                                                                                  \n dense_10 (Dense)            (None, 144)                  103824    ['dropout_9[0][0]']           \n                                                                                                  \n dense_11 (Dense)            (None, 1)                    145       ['dense_10[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 30299809 (115.58 MB)\nTrainable params: 299809 (1.14 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 96s 115ms/step - loss: 0.2505 - accuracy: 0.8986 - val_loss: 0.1663 - val_accuracy: 0.9337\nEpoch 2/4\n789/789 [==============================] - 88s 112ms/step - loss: 0.2149 - accuracy: 0.9108 - val_loss: 0.1619 - val_accuracy: 0.9348\nEpoch 3/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.2043 - accuracy: 0.9146 - val_loss: 0.1562 - val_accuracy: 0.9361\nEpoch 4/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.1978 - accuracy: 0.9175 - val_loss: 0.1550 - val_accuracy: 0.9363\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9254080494365664\nModel: \"model_6\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_7 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_6 (Embedding)     (None, 350, 300)             3000000   ['input_7[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_6 (Spati  (None, 350, 300)             0         ['embedding_6[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_12 (Bidirect  (None, 350, 120)             130320    ['spatial_dropout1d_6[0][0]'] \n ional)                                                                                           \n                                                                                                  \n bidirectional_13 (Bidirect  (None, 350, 120)             65520     ['bidirectional_12[0][0]']    \n ional)                                                                                           \n                                                                                                  \n concatenate_8 (Concatenate  (None, 350, 240)             0         ['bidirectional_12[0][0]',    \n )                                                                   'bidirectional_13[0][0]']    \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_8[0][0]']       \n                                                                                                  \n global_max_pooling1d_6 (Gl  (None, 240)                  0         ['concatenate_8[0][0]']       \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_6  (None, 240)                  0         ['concatenate_8[0][0]']       \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n concatenate_9 (Concatenate  (None, 720)                  0         ['last[0][0]',                \n )                                                                   'global_max_pooling1d_6[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_6[0\n                                                                    ][0]']                        \n                                                                                                  \n dropout_10 (Dropout)        (None, 720)                  0         ['concatenate_9[0][0]']       \n                                                                                                  \n dense_12 (Dense)            (None, 144)                  103824    ['dropout_10[0][0]']          \n                                                                                                  \n dense_13 (Dense)            (None, 1)                    145       ['dense_12[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 30299809 (115.58 MB)\nTrainable params: 299809 (1.14 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 95s 113ms/step - loss: 0.2451 - accuracy: 0.9004 - val_loss: 0.2130 - val_accuracy: 0.9113\nEpoch 2/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.2077 - accuracy: 0.9135 - val_loss: 0.1877 - val_accuracy: 0.9230\nEpoch 3/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.1975 - accuracy: 0.9178 - val_loss: 0.2001 - val_accuracy: 0.9181\nEpoch 4/4\n789/789 [==============================] - 88s 112ms/step - loss: 0.1916 - accuracy: 0.9199 - val_loss: 0.1864 - val_accuracy: 0.9246\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9046539894896939\nModel: \"model_7\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_8 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_7 (Embedding)     (None, 350, 300)             3000000   ['input_8[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_7 (Spati  (None, 350, 300)             0         ['embedding_7[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_14 (Bidirect  (None, 350, 120)             130320    ['spatial_dropout1d_7[0][0]'] \n ional)                                                                                           \n                                                                                                  \n bidirectional_15 (Bidirect  (None, 350, 120)             65520     ['bidirectional_14[0][0]']    \n ional)                                                                                           \n                                                                                                  \n concatenate_10 (Concatenat  (None, 350, 240)             0         ['bidirectional_14[0][0]',    \n e)                                                                  'bidirectional_15[0][0]']    \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_10[0][0]']      \n                                                                                                  \n global_max_pooling1d_7 (Gl  (None, 240)                  0         ['concatenate_10[0][0]']      \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_7  (None, 240)                  0         ['concatenate_10[0][0]']      \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n concatenate_11 (Concatenat  (None, 720)                  0         ['last[0][0]',                \n e)                                                                  'global_max_pooling1d_7[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_7[0\n                                                                    ][0]']                        \n                                                                                                  \n dropout_11 (Dropout)        (None, 720)                  0         ['concatenate_11[0][0]']      \n                                                                                                  \n dense_14 (Dense)            (None, 144)                  103824    ['dropout_11[0][0]']          \n                                                                                                  \n dense_15 (Dense)            (None, 1)                    145       ['dense_14[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 30299809 (115.58 MB)\nTrainable params: 299809 (1.14 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 95s 113ms/step - loss: 0.2314 - accuracy: 0.9066 - val_loss: 0.2440 - val_accuracy: 0.9008\nEpoch 2/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.1931 - accuracy: 0.9196 - val_loss: 0.2424 - val_accuracy: 0.8990\nEpoch 3/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.1834 - accuracy: 0.9236 - val_loss: 0.2318 - val_accuracy: 0.9017\nEpoch 4/4\n789/789 [==============================] - 88s 111ms/step - loss: 0.1761 - accuracy: 0.9268 - val_loss: 0.2217 - val_accuracy: 0.9083\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.8851998514123599\nPredicting val results...\n177/177 [==============================] - 6s 37ms/step\n177/177 [==============================] - 6s 37ms/step\n177/177 [==============================] - 6s 37ms/step\n177/177 [==============================] - 6s 37ms/step\nmale_1: 0.8948583420776496\nfemale_1: 0.9064674927856051\nLGBTQ_1: 0.8057652711050103\nchristian_1: 0.9318681318681319\nmuslim_1: 0.8170616113744076\nother_religions_1: 0.8701825557809331\nblack_1: 0.761501210653753\nwhite_1: 0.7854900592954308\nFold_WGA: 0.761501210653753\nmale_1: 0.8986358866736621\nfemale_1: 0.9056187404515362\nLGBTQ_1: 0.8037062457103638\nchristian_1: 0.9314285714285714\nmuslim_1: 0.8218009478672986\nother_religions_1: 0.8640973630831643\nblack_1: 0.7663438256658596\nwhite_1: 0.7896756191140565\nFold_WGA: 0.7663438256658596\nmale_1: 0.8931794333683106\nfemale_1: 0.9049397385842811\nLGBTQ_1: 0.8037062457103638\nchristian_1: 0.9307692307692308\nmuslim_1: 0.8255924170616113\nother_religions_1: 0.859026369168357\nblack_1: 0.7639225181598063\nwhite_1: 0.7802581095221486\nFold_WGA: 0.7639225181598063\nmale_1: 0.8977964323189926\nfemale_1: 0.9069767441860465\nLGBTQ_1: 0.7995881949210707\nchristian_1: 0.9318681318681319\nmuslim_1: 0.8293838862559242\nother_religions_1: 0.8630831643002028\nblack_1: 0.763317191283293\nwhite_1: 0.7886292291594\nFold_WGA: 0.763317191283293\n","output_type":"stream"}]},{"cell_type":"code","source":"GRU_score, GRU_train_pred, GRU_val_pred, GRU_test_pred = save_single_model(models, val_x, test_x, fold_predictions, folds_WGA, 'GRU')","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:58:42.010893Z","iopub.execute_input":"2024-01-25T13:58:42.011615Z","iopub.status.idle":"2024-01-25T14:00:28.692605Z","shell.execute_reply.started":"2024-01-25T13:58:42.011580Z","shell.execute_reply":"2024-01-25T14:00:28.691679Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"177/177 [==============================] - 7s 37ms/step\n523/523 [==============================] - 19s 37ms/step\n177/177 [==============================] - 7s 37ms/step\n523/523 [==============================] - 19s 37ms/step\n177/177 [==============================] - 6s 36ms/step\n523/523 [==============================] - 19s 37ms/step\n177/177 [==============================] - 6s 37ms/step\n523/523 [==============================] - 19s 37ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"GRU_score","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:49:33.306680Z","iopub.execute_input":"2024-01-25T14:49:33.307017Z","iopub.status.idle":"2024-01-25T14:49:33.312851Z","shell.execute_reply.started":"2024-01-25T14:49:33.306993Z","shell.execute_reply":"2024-01-25T14:49:33.311709Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"[0.761501210653753, 0.7663438256658596, 0.7639225181598063, 0.763317191283293]"},"metadata":{}}]},{"cell_type":"code","source":"MODEL_CHECKPOINT_FOLDER = \"checkpoints/\"\nTEMPORARY_CHECKPOINTS_PATH = 'temporary_checkpoints/'\nnb_words = min(MAX_FEATURES, len(word_index))\ndef get_model():\n    return  get_gru_rnn_attention(nb_words, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, out_size=1)\n\ntrainer = Trainer(model_stamp='gru_attn_rnn', epoch_num=4, learning_rate=1e-3)\nmodels,val_loss,total_auc,fold_predictions = trainer.train_folds(X=train_x, y=train_y, fold_count=4, batch_size=256, get_model_func=get_model)\nprint(\"Predicting val results...\")\nLSTM_val_predicts = []\nfor fold_id, model in enumerate(models):\n    val_predicts = model.predict(val_x, batch_size=256, verbose=1)\n    LSTM_val_predicts.append(val_predicts)\nval_y_test = pd.read_csv(os.path.join(dirname, 'val_y.csv'))\nfolds_WGA = []\nfor fold in LSTM_val_predicts:\n    pred_df = pd.DataFrame()\n    pred_df['pred'] = [val[-1] for val in fold]\n    pred_df = pred_df.reset_index()\n    metric = worst_group_accuracy(pred_df, val_y_test)\n    print(f'Fold_WGA: {metric}')\n    folds_WGA.append(metric)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:00:34.059587Z","iopub.execute_input":"2024-01-25T14:00:34.059917Z","iopub.status.idle":"2024-01-25T14:28:57.272733Z","shell.execute_reply.started":"2024-01-25T14:00:34.059893Z","shell.execute_reply":"2024-01-25T14:28:57.271823Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"model_8\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_9 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_8 (Embedding)     (None, 350, 300)             3000000   ['input_9[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_8 (Spati  (None, 350, 300)             0         ['embedding_8[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_16 (Bidirect  (None, 350, 120)             130320    ['spatial_dropout1d_8[0][0]'] \n ional)                                                                                           \n                                                                                                  \n bidirectional_17 (Bidirect  (None, 350, 120)             65520     ['bidirectional_16[0][0]']    \n ional)                                                                                           \n                                                                                                  \n concatenate_12 (Concatenat  (None, 350, 240)             0         ['bidirectional_16[0][0]',    \n e)                                                                  'bidirectional_17[0][0]']    \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_12[0][0]']      \n                                                                                                  \n global_max_pooling1d_8 (Gl  (None, 240)                  0         ['concatenate_12[0][0]']      \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_8  (None, 240)                  0         ['concatenate_12[0][0]']      \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n attention_weighted_average  (None, 240)                  240       ['concatenate_12[0][0]']      \n  (AttentionWeightedAverage                                                                       \n )                                                                                                \n                                                                                                  \n concatenate_13 (Concatenat  (None, 960)                  0         ['last[0][0]',                \n e)                                                                  'global_max_pooling1d_8[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_8[0\n                                                                    ][0]',                        \n                                                                     'attention_weighted_average[0\n                                                                    ][0]']                        \n                                                                                                  \n dropout_12 (Dropout)        (None, 960)                  0         ['concatenate_13[0][0]']      \n                                                                                                  \n dense_16 (Dense)            (None, 144)                  138384    ['dropout_12[0][0]']          \n                                                                                                  \n dense_17 (Dense)            (None, 1)                    145       ['dense_16[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 30334609 (115.72 MB)\nTrainable params: 334609 (1.28 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 102s 122ms/step - loss: 0.2239 - accuracy: 0.9195 - val_loss: 0.2764 - val_accuracy: 0.8405\nEpoch 2/4\n789/789 [==============================] - 93s 118ms/step - loss: 0.1983 - accuracy: 0.9216 - val_loss: 0.2510 - val_accuracy: 0.8827\nEpoch 3/4\n789/789 [==============================] - 93s 118ms/step - loss: 0.1921 - accuracy: 0.9233 - val_loss: 0.2171 - val_accuracy: 0.9084\nEpoch 4/4\n789/789 [==============================] - 92s 117ms/step - loss: 0.1869 - accuracy: 0.9246 - val_loss: 0.2211 - val_accuracy: 0.9072\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9694896007507406\nModel: \"model_9\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_10 (InputLayer)       [(None, 350)]                0         []                            \n                                                                                                  \n embedding_9 (Embedding)     (None, 350, 300)             3000000   ['input_10[0][0]']            \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_9 (Spati  (None, 350, 300)             0         ['embedding_9[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_18 (Bidirect  (None, 350, 120)             130320    ['spatial_dropout1d_9[0][0]'] \n ional)                                                                                           \n                                                                                                  \n bidirectional_19 (Bidirect  (None, 350, 120)             65520     ['bidirectional_18[0][0]']    \n ional)                                                                                           \n                                                                                                  \n concatenate_14 (Concatenat  (None, 350, 240)             0         ['bidirectional_18[0][0]',    \n e)                                                                  'bidirectional_19[0][0]']    \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_14[0][0]']      \n                                                                                                  \n global_max_pooling1d_9 (Gl  (None, 240)                  0         ['concatenate_14[0][0]']      \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_9  (None, 240)                  0         ['concatenate_14[0][0]']      \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n attention_weighted_average  (None, 240)                  240       ['concatenate_14[0][0]']      \n _1 (AttentionWeightedAvera                                                                       \n ge)                                                                                              \n                                                                                                  \n concatenate_15 (Concatenat  (None, 960)                  0         ['last[0][0]',                \n e)                                                                  'global_max_pooling1d_9[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_9[0\n                                                                    ][0]',                        \n                                                                     'attention_weighted_average_1\n                                                                    [0][0]']                      \n                                                                                                  \n dropout_13 (Dropout)        (None, 960)                  0         ['concatenate_15[0][0]']      \n                                                                                                  \n dense_18 (Dense)            (None, 144)                  138384    ['dropout_13[0][0]']          \n                                                                                                  \n dense_19 (Dense)            (None, 1)                    145       ['dense_18[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 30334609 (115.72 MB)\nTrainable params: 334609 (1.28 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 100s 119ms/step - loss: 0.2485 - accuracy: 0.8997 - val_loss: 0.1717 - val_accuracy: 0.9342\nEpoch 2/4\n789/789 [==============================] - 92s 117ms/step - loss: 0.2125 - accuracy: 0.9122 - val_loss: 0.1584 - val_accuracy: 0.9358\nEpoch 3/4\n789/789 [==============================] - 93s 117ms/step - loss: 0.2040 - accuracy: 0.9156 - val_loss: 0.1570 - val_accuracy: 0.9360\nEpoch 4/4\n789/789 [==============================] - 93s 117ms/step - loss: 0.1963 - accuracy: 0.9183 - val_loss: 0.1559 - val_accuracy: 0.9359\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9240279910889933\nModel: \"model_10\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_11 (InputLayer)       [(None, 350)]                0         []                            \n                                                                                                  \n embedding_10 (Embedding)    (None, 350, 300)             3000000   ['input_11[0][0]']            \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_10 (Spat  (None, 350, 300)             0         ['embedding_10[0][0]']        \n ialDropout1D)                                                                                    \n                                                                                                  \n bidirectional_20 (Bidirect  (None, 350, 120)             130320    ['spatial_dropout1d_10[0][0]']\n ional)                                                                                           \n                                                                                                  \n bidirectional_21 (Bidirect  (None, 350, 120)             65520     ['bidirectional_20[0][0]']    \n ional)                                                                                           \n                                                                                                  \n concatenate_16 (Concatenat  (None, 350, 240)             0         ['bidirectional_20[0][0]',    \n e)                                                                  'bidirectional_21[0][0]']    \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_16[0][0]']      \n                                                                                                  \n global_max_pooling1d_10 (G  (None, 240)                  0         ['concatenate_16[0][0]']      \n lobalMaxPooling1D)                                                                               \n                                                                                                  \n global_average_pooling1d_1  (None, 240)                  0         ['concatenate_16[0][0]']      \n 0 (GlobalAveragePooling1D)                                                                       \n                                                                                                  \n attention_weighted_average  (None, 240)                  240       ['concatenate_16[0][0]']      \n _2 (AttentionWeightedAvera                                                                       \n ge)                                                                                              \n                                                                                                  \n concatenate_17 (Concatenat  (None, 960)                  0         ['last[0][0]',                \n e)                                                                  'global_max_pooling1d_10[0][0\n                                                                    ]',                           \n                                                                     'global_average_pooling1d_10[\n                                                                    0][0]',                       \n                                                                     'attention_weighted_average_2\n                                                                    [0][0]']                      \n                                                                                                  \n dropout_14 (Dropout)        (None, 960)                  0         ['concatenate_17[0][0]']      \n                                                                                                  \n dense_20 (Dense)            (None, 144)                  138384    ['dropout_14[0][0]']          \n                                                                                                  \n dense_21 (Dense)            (None, 1)                    145       ['dense_20[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 30334609 (115.72 MB)\nTrainable params: 334609 (1.28 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 100s 119ms/step - loss: 0.2406 - accuracy: 0.9030 - val_loss: 0.1876 - val_accuracy: 0.9246\nEpoch 2/4\n789/789 [==============================] - 93s 118ms/step - loss: 0.2053 - accuracy: 0.9148 - val_loss: 0.1822 - val_accuracy: 0.9270\nEpoch 3/4\n789/789 [==============================] - 93s 118ms/step - loss: 0.1949 - accuracy: 0.9188 - val_loss: 0.1807 - val_accuracy: 0.9268\nEpoch 4/4\n789/789 [==============================] - 92s 117ms/step - loss: 0.1886 - accuracy: 0.9208 - val_loss: 0.1946 - val_accuracy: 0.9198\n2102/2102 [==============================] - 35s 16ms/step\nAUC Score 0.9073309002876946\nModel: \"model_11\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_12 (InputLayer)       [(None, 350)]                0         []                            \n                                                                                                  \n embedding_11 (Embedding)    (None, 350, 300)             3000000   ['input_12[0][0]']            \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_11 (Spat  (None, 350, 300)             0         ['embedding_11[0][0]']        \n ialDropout1D)                                                                                    \n                                                                                                  \n bidirectional_22 (Bidirect  (None, 350, 120)             130320    ['spatial_dropout1d_11[0][0]']\n ional)                                                                                           \n                                                                                                  \n bidirectional_23 (Bidirect  (None, 350, 120)             65520     ['bidirectional_22[0][0]']    \n ional)                                                                                           \n                                                                                                  \n concatenate_18 (Concatenat  (None, 350, 240)             0         ['bidirectional_22[0][0]',    \n e)                                                                  'bidirectional_23[0][0]']    \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_18[0][0]']      \n                                                                                                  \n global_max_pooling1d_11 (G  (None, 240)                  0         ['concatenate_18[0][0]']      \n lobalMaxPooling1D)                                                                               \n                                                                                                  \n global_average_pooling1d_1  (None, 240)                  0         ['concatenate_18[0][0]']      \n 1 (GlobalAveragePooling1D)                                                                       \n                                                                                                  \n attention_weighted_average  (None, 240)                  240       ['concatenate_18[0][0]']      \n _3 (AttentionWeightedAvera                                                                       \n ge)                                                                                              \n                                                                                                  \n concatenate_19 (Concatenat  (None, 960)                  0         ['last[0][0]',                \n e)                                                                  'global_max_pooling1d_11[0][0\n                                                                    ]',                           \n                                                                     'global_average_pooling1d_11[\n                                                                    0][0]',                       \n                                                                     'attention_weighted_average_3\n                                                                    [0][0]']                      \n                                                                                                  \n dropout_15 (Dropout)        (None, 960)                  0         ['concatenate_19[0][0]']      \n                                                                                                  \n dense_22 (Dense)            (None, 144)                  138384    ['dropout_15[0][0]']          \n                                                                                                  \n dense_23 (Dense)            (None, 1)                    145       ['dense_22[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 30334609 (115.72 MB)\nTrainable params: 334609 (1.28 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n789/789 [==============================] - 100s 119ms/step - loss: 0.2270 - accuracy: 0.9090 - val_loss: 0.2446 - val_accuracy: 0.8958\nEpoch 2/4\n789/789 [==============================] - 93s 118ms/step - loss: 0.1919 - accuracy: 0.9204 - val_loss: 0.2236 - val_accuracy: 0.9104\nEpoch 3/4\n789/789 [==============================] - 93s 117ms/step - loss: 0.1812 - accuracy: 0.9246 - val_loss: 0.2404 - val_accuracy: 0.8961\nEpoch 4/4\n789/789 [==============================] - 93s 118ms/step - loss: 0.1744 - accuracy: 0.9273 - val_loss: 0.2201 - val_accuracy: 0.9087\n2102/2102 [==============================] - 36s 16ms/step\nAUC Score 0.8853065910963176\nPredicting val results...\n177/177 [==============================] - 7s 38ms/step\n177/177 [==============================] - 7s 38ms/step\n177/177 [==============================] - 7s 38ms/step\n177/177 [==============================] - 7s 38ms/step\nmale_1: 0.8969569779643232\nfemale_1: 0.9064674927856051\nLGBTQ_1: 0.8064516129032258\nchristian_1: 0.9305494505494506\nmuslim_1: 0.8170616113744076\nother_religions_1: 0.8630831643002028\nblack_1: 0.7645278450363197\nwhite_1: 0.781304499476805\nFold_WGA: 0.7645278450363197\nmale_1: 0.8967471143756558\nfemale_1: 0.9046002376506536\nLGBTQ_1: 0.8057652711050103\nchristian_1: 0.932967032967033\nmuslim_1: 0.8218009478672986\nother_religions_1: 0.8620689655172413\nblack_1: 0.7736077481840193\nwhite_1: 0.7914196023718172\nFold_WGA: 0.7736077481840193\nmale_1: 0.8948583420776496\nfemale_1: 0.9022237311152606\nLGBTQ_1: 0.7995881949210707\nchristian_1: 0.9327472527472528\nmuslim_1: 0.8218009478672986\nother_religions_1: 0.8580121703853956\nblack_1: 0.7584745762711864\nwhite_1: 0.7830484827345657\nFold_WGA: 0.7584745762711864\nmale_1: 0.8994753410283316\nfemale_1: 0.9030724834493294\nLGBTQ_1: 0.8057652711050103\nchristian_1: 0.930989010989011\nmuslim_1: 0.8312796208530806\nother_religions_1: 0.8539553752535497\nblack_1: 0.7760290556900726\nwhite_1: 0.7970003487966516\nFold_WGA: 0.7760290556900726\n","output_type":"stream"}]},{"cell_type":"code","source":"GRU_attn_score, GRU_attn_train_pred, GRU_attn_val_pred, GRU_attn_test_pred = save_single_model(models, val_x, test_x, fold_predictions, folds_WGA, 'GRU_attn')","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:29:04.826242Z","iopub.execute_input":"2024-01-25T14:29:04.826621Z","iopub.status.idle":"2024-01-25T14:30:56.129927Z","shell.execute_reply.started":"2024-01-25T14:29:04.826592Z","shell.execute_reply":"2024-01-25T14:30:56.129120Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"177/177 [==============================] - 7s 39ms/step\n523/523 [==============================] - 20s 39ms/step\n177/177 [==============================] - 7s 39ms/step\n523/523 [==============================] - 20s 38ms/step\n177/177 [==============================] - 7s 38ms/step\n523/523 [==============================] - 20s 38ms/step\n177/177 [==============================] - 7s 38ms/step\n523/523 [==============================] - 20s 38ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"GRU_attn_score","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:49:13.729787Z","iopub.execute_input":"2024-01-25T14:49:13.730155Z","iopub.status.idle":"2024-01-25T14:49:13.738309Z","shell.execute_reply.started":"2024-01-25T14:49:13.730125Z","shell.execute_reply":"2024-01-25T14:49:13.737116Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[0.7645278450363197,\n 0.7736077481840193,\n 0.7584745762711864,\n 0.7760290556900726]"},"metadata":{}}]},{"cell_type":"code","source":"train_x = pd.DataFrame()\ntrain_x['LSTM'] = [val[0] for val in LSTM_train_pred]\ntrain_x['GRU'] = [val[0] for val in GRU_train_pred]\ntrain_x['GRU_attn'] = [val[0] for val in GRU_attn_train_pred]\ntrain_x","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:35:53.285837Z","iopub.execute_input":"2024-01-25T14:35:53.286764Z","iopub.status.idle":"2024-01-25T14:35:54.020113Z","shell.execute_reply.started":"2024-01-25T14:35:53.286725Z","shell.execute_reply":"2024-01-25T14:35:54.019236Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"            LSTM       GRU  GRU_attn\n0       0.469449  0.350979  0.369549\n1       0.202535  0.290206  0.408400\n2       0.622117  0.692984  0.654164\n3       0.438028  0.553940  0.469837\n4       0.640644  0.622073  0.664755\n...          ...       ...       ...\n269033  0.239672  0.218813  0.231567\n269034  0.255629  0.316450  0.217420\n269035  0.014334  0.021539  0.006388\n269036  0.107205  0.176530  0.095793\n269037  0.523467  0.490948  0.453003\n\n[269038 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LSTM</th>\n      <th>GRU</th>\n      <th>GRU_attn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.469449</td>\n      <td>0.350979</td>\n      <td>0.369549</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.202535</td>\n      <td>0.290206</td>\n      <td>0.408400</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.622117</td>\n      <td>0.692984</td>\n      <td>0.654164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.438028</td>\n      <td>0.553940</td>\n      <td>0.469837</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.640644</td>\n      <td>0.622073</td>\n      <td>0.664755</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>269033</th>\n      <td>0.239672</td>\n      <td>0.218813</td>\n      <td>0.231567</td>\n    </tr>\n    <tr>\n      <th>269034</th>\n      <td>0.255629</td>\n      <td>0.316450</td>\n      <td>0.217420</td>\n    </tr>\n    <tr>\n      <th>269035</th>\n      <td>0.014334</td>\n      <td>0.021539</td>\n      <td>0.006388</td>\n    </tr>\n    <tr>\n      <th>269036</th>\n      <td>0.107205</td>\n      <td>0.176530</td>\n      <td>0.095793</td>\n    </tr>\n    <tr>\n      <th>269037</th>\n      <td>0.523467</td>\n      <td>0.490948</td>\n      <td>0.453003</td>\n    </tr>\n  </tbody>\n</table>\n<p>269038 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"val_x = pd.DataFrame()\nval_x['LSTM'] = [val[0] for val in LSTM_val_pred]\nval_x['GRU'] = [val[0] for val in GRU_val_pred]\nval_x['GRU_attn'] = [val[0] for val in GRU_attn_val_pred]\nval_x","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:41:46.796215Z","iopub.execute_input":"2024-01-25T14:41:46.796906Z","iopub.status.idle":"2024-01-25T14:41:46.914952Z","shell.execute_reply.started":"2024-01-25T14:41:46.796871Z","shell.execute_reply":"2024-01-25T14:41:46.914052Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"           LSTM       GRU  GRU_attn\n0      0.855428  0.903790  0.907688\n1      0.796110  0.810574  0.866206\n2      0.845888  0.898856  0.888335\n3      0.374033  0.503030  0.471473\n4      0.669301  0.596998  0.652607\n...         ...       ...       ...\n45175  0.098179  0.069736  0.035183\n45176  0.080056  0.050775  0.097586\n45177  0.144540  0.169164  0.181009\n45178  0.101906  0.086000  0.054459\n45179  0.090552  0.065368  0.146085\n\n[45180 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LSTM</th>\n      <th>GRU</th>\n      <th>GRU_attn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.855428</td>\n      <td>0.903790</td>\n      <td>0.907688</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.796110</td>\n      <td>0.810574</td>\n      <td>0.866206</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.845888</td>\n      <td>0.898856</td>\n      <td>0.888335</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.374033</td>\n      <td>0.503030</td>\n      <td>0.471473</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.669301</td>\n      <td>0.596998</td>\n      <td>0.652607</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45175</th>\n      <td>0.098179</td>\n      <td>0.069736</td>\n      <td>0.035183</td>\n    </tr>\n    <tr>\n      <th>45176</th>\n      <td>0.080056</td>\n      <td>0.050775</td>\n      <td>0.097586</td>\n    </tr>\n    <tr>\n      <th>45177</th>\n      <td>0.144540</td>\n      <td>0.169164</td>\n      <td>0.181009</td>\n    </tr>\n    <tr>\n      <th>45178</th>\n      <td>0.101906</td>\n      <td>0.086000</td>\n      <td>0.054459</td>\n    </tr>\n    <tr>\n      <th>45179</th>\n      <td>0.090552</td>\n      <td>0.065368</td>\n      <td>0.146085</td>\n    </tr>\n  </tbody>\n</table>\n<p>45180 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nmodel = SVC()\nmodel.fit(train_x, train_y)\npredictions = model.predict(val_x)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:58:21.497431Z","iopub.execute_input":"2024-01-25T14:58:21.497763Z","iopub.status.idle":"2024-01-25T14:58:23.261842Z","shell.execute_reply.started":"2024-01-25T14:58:21.497735Z","shell.execute_reply":"2024-01-25T14:58:23.260340Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m SVC()\n\u001b[0;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_x\u001b[49m, train_y)\n\u001b[1;32m      7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_x)\n","\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"],"ename":"NameError","evalue":"name 'train_x' is not defined","output_type":"error"}]},{"cell_type":"code","source":"stacking_val_pred = pd.DataFrame()\nstacking_val_pred['pred'] = [val[0] for val in predictions]\nstacking_val_pred = stacking_val_pred.reset_index()\nstacking_val_pred","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:48:05.967982Z","iopub.execute_input":"2024-01-25T14:48:05.968835Z","iopub.status.idle":"2024-01-25T14:48:06.027774Z","shell.execute_reply.started":"2024-01-25T14:48:05.968801Z","shell.execute_reply":"2024-01-25T14:48:06.026906Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"       index      pred\n0          0  0.946137\n1          1  0.872145\n2          2  0.935203\n3          3  0.476243\n4          4  0.673089\n...      ...       ...\n45175  45175  0.064982\n45176  45176  0.067351\n45177  45177  0.165959\n45178  45178  0.078862\n45179  45179  0.090972\n\n[45180 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.946137</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.872145</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.935203</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.476243</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.673089</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45175</th>\n      <td>45175</td>\n      <td>0.064982</td>\n    </tr>\n    <tr>\n      <th>45176</th>\n      <td>45176</td>\n      <td>0.067351</td>\n    </tr>\n    <tr>\n      <th>45177</th>\n      <td>45177</td>\n      <td>0.165959</td>\n    </tr>\n    <tr>\n      <th>45178</th>\n      <td>45178</td>\n      <td>0.078862</td>\n    </tr>\n    <tr>\n      <th>45179</th>\n      <td>45179</td>\n      <td>0.090972</td>\n    </tr>\n  </tbody>\n</table>\n<p>45180 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stacking_metric = worst_group_accuracy(stacking_val_pred, val_y_test)\nprint(f'stacking WGA: {stacking_metric}')","metadata":{"execution":{"iopub.status.busy":"2024-01-25T14:48:08.583413Z","iopub.execute_input":"2024-01-25T14:48:08.583770Z","iopub.status.idle":"2024-01-25T14:48:08.620799Z","shell.execute_reply.started":"2024-01-25T14:48:08.583744Z","shell.execute_reply":"2024-01-25T14:48:08.619958Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"male_1: 0.9003147953830011\nfemale_1: 0.9088439993209981\nLGBTQ_1: 0.8071379547014413\nchristian_1: 0.9331868131868132\nmuslim_1: 0.8298578199052132\nother_religions_1: 0.8640973630831643\nblack_1: 0.7772397094430993\nwhite_1: 0.7907220090687129\nstacking WGA: 0.7772397094430993\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-01-25T18:33:23.010438Z","iopub.execute_input":"2024-01-25T18:33:23.011198Z","iopub.status.idle":"2024-01-25T18:33:23.023916Z","shell.execute_reply.started":"2024-01-25T18:33:23.011165Z","shell.execute_reply":"2024-01-25T18:33:23.022851Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"MODEL_CHECKPOINT_FOLDER = \"checkpoints/\"\nTEMPORARY_CHECKPOINTS_PATH = 'temporary_checkpoints/'\nnb_words = min(MAX_FEATURES, len(word_index))\ndef get_model():\n    return  get_textCNN(nb_words, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, out_size=1)\n\ntrainer = Trainer(model_stamp='textCNN', epoch_num=4, learning_rate=1e-3)\nmodels,val_loss,total_auc,fold_predictions = trainer.train_folds(X=train_x, y=train_y, fold_count=4, batch_size=256, get_model_func=get_model)\nprint(\"Predicting val results...\")\nLSTM_val_predicts = []\nfor fold_id, model in enumerate(models):\n    val_predicts = model.predict(val_x, batch_size=256, verbose=1)\n    LSTM_val_predicts.append(val_predicts)\nval_y_test = pd.read_csv(os.path.join(dirname, 'val_y.csv'))\nfolds_WGA = []\nfor fold in LSTM_val_predicts:\n    pred_df = pd.DataFrame()\n    pred_df['pred'] = [val[-1] for val in fold]\n    pred_df = pred_df.reset_index()\n    metric = worst_group_accuracy(pred_df, val_y_test)\n    print(f'Fold_WGA: {metric}')\n    folds_WGA.append(metric)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T18:33:23.540580Z","iopub.execute_input":"2024-01-25T18:33:23.540939Z","iopub.status.idle":"2024-01-25T18:33:33.147640Z","shell.execute_reply.started":"2024-01-25T18:33:23.540911Z","shell.execute_reply":"2024-01-25T18:33:33.145994Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_3 (InputLayer)        [(None, 350)]                0         []                            \n                                                                                                  \n embedding_2 (Embedding)     (None, 350, 300)             3000000   ['input_3[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_2 (Spati  (None, 350, 300)             0         ['embedding_2[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n reshape_1 (Reshape)         (None, 350, 300, 1)          0         ['spatial_dropout1d_2[0][0]'] \n                                                                                                  \n conv2d (Conv2D)             (None, 350, 1, 32)           9632      ['reshape_1[0][0]']           \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 349, 1, 32)           19232     ['reshape_1[0][0]']           \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 348, 1, 32)           28832     ['reshape_1[0][0]']           \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 346, 1, 32)           48032     ['reshape_1[0][0]']           \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 1, 1, 32)             0         ['conv2d[0][0]']              \n D)                                                                                               \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 1, 1, 32)             0         ['conv2d_1[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 1, 1, 32)             0         ['conv2d_2[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n max_pooling2d_3 (MaxPoolin  (None, 1, 1, 32)             0         ['conv2d_3[0][0]']            \n g2D)                                                                                             \n                                                                                                  \n concatenate (Concatenate)   (None, 4, 1, 32)             0         ['max_pooling2d[0][0]',       \n                                                                     'max_pooling2d_1[0][0]',     \n                                                                     'max_pooling2d_2[0][0]',     \n                                                                     'max_pooling2d_3[0][0]']     \n                                                                                                  \n flatten (Flatten)           (None, 128)                  0         ['concatenate[0][0]']         \n                                                                                                  \n dropout (Dropout)           (None, 128)                  0         ['flatten[0][0]']             \n                                                                                                  \n dense (Dense)               (None, 1)                    129       ['dropout[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 30105857 (114.84 MB)\nTrainable params: 105857 (413.50 KB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/4\n108/789 [===>..........................] - ETA: 24s - loss: 0.2803 - accuracy: 0.9150","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  get_textCNN(nb_words, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, out_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model_stamp\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextCNN\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m models,val_loss,total_auc,fold_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_model_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting val results...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m LSTM_val_predicts \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/kaggle/working/Train.py:56\u001b[0m, in \u001b[0;36mTrainer.train_folds\u001b[0;34m(self, X, y, fold_count, batch_size, get_model_func)\u001b[0m\n\u001b[1;32m     52\u001b[0m val_x \u001b[38;5;241m=\u001b[39m X[fold_start:fold_end]\n\u001b[1;32m     53\u001b[0m val_y \u001b[38;5;241m=\u001b[39m y[fold_start:fold_end]\n\u001b[0;32m---> 56\u001b[0m model, bst_val_score, auc, fold_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model_by_logloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_model_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bst_val_score\n\u001b[1;32m     59\u001b[0m total_auc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m auc\n","File \u001b[0;32m/kaggle/working/Train.py:72\u001b[0m, in \u001b[0;36mTrainer._train_model_by_logloss\u001b[0;34m(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id)\u001b[0m\n\u001b[1;32m     70\u001b[0m bst_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_stamp \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(fold_id) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     71\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(bst_model_path, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 72\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m bst_val_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     77\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1748\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1746\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1747\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1748\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest.py:624\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1054\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1054\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1094\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1089\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1090\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1093\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1094\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1095\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1096\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1141\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1107\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1106\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}