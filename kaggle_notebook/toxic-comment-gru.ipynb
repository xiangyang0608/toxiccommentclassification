{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7464547,"sourceType":"datasetVersion","datasetId":4281512}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-24T21:59:08.498194Z","iopub.execute_input":"2024-01-24T21:59:08.498469Z","iopub.status.idle":"2024-01-24T21:59:08.890150Z","shell.execute_reply.started":"2024-01-24T21:59:08.498444Z","shell.execute_reply":"2024-01-24T21:59:08.888981Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dl-kaggle-dataset/cleaned_train_x.csv\n/kaggle/input/dl-kaggle-dataset/cleaned_val_x.csv\n/kaggle/input/dl-kaggle-dataset/Train.py\n/kaggle/input/dl-kaggle-dataset/cleaned_test_x.csv\n/kaggle/input/dl-kaggle-dataset/train_y.csv\n/kaggle/input/dl-kaggle-dataset/train_x.csv\n/kaggle/input/dl-kaggle-dataset/test_x.csv\n/kaggle/input/dl-kaggle-dataset/glove.840B.300d.txt\n/kaggle/input/dl-kaggle-dataset/DataPreprocessing.py\n/kaggle/input/dl-kaggle-dataset/val_x.csv\n/kaggle/input/dl-kaggle-dataset/val_y.csv\n/kaggle/input/dl-kaggle-dataset/rnn_baseline.py\n/kaggle/input/dl-kaggle-dataset/cleanwords.txt\n/kaggle/input/dl-kaggle-dataset/DataLoader.py\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:00:30.002795Z","iopub.execute_input":"2024-01-24T22:00:30.003525Z","iopub.status.idle":"2024-01-24T22:00:30.009103Z","shell.execute_reply.started":"2024-01-24T22:00:30.003495Z","shell.execute_reply":"2024-01-24T22:00:30.008036Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"GPU is available\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torchmetrics import AUROC, F1Score\nfrom keras.preprocessing.text import Tokenizer\n\n# import module we'll need to import our custom module\nfrom shutil import copyfile\n# copy our file into the working directory (make sure it has .py suffix)\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/DataLoader.py\", dst = \"../working/DataLoader.py\")\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/rnn_baseline.py\", dst = \"../working/rnn_baseline.py\")\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/Train.py\", dst = \"../working/Train.py\")\ncopyfile(src = \"/kaggle/input/dl-kaggle-dataset/DataPreprocessing.py\", dst = \"../working/DataPreprocessing.py\")\n# import all our functions\nfrom DataLoader import DataLoader\nfrom rnn_baseline import get_av_rnn\nfrom Train import Trainer\nfrom DataPreprocessing import get_clean_word_dict, get_clean_data","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:00:31.717210Z","iopub.execute_input":"2024-01-24T22:00:31.717630Z","iopub.status.idle":"2024-01-24T22:00:31.744316Z","shell.execute_reply.started":"2024-01-24T22:00:31.717584Z","shell.execute_reply":"2024-01-24T22:00:31.743142Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"cl_path = (os.path.join(dirname, 'cleanwords.txt'))\nclean_word_dict = get_clean_word_dict(cl_path)\nglove_path = os.path.join(dirname, 'glove.840B.300d.txt')\nembedding_path = [glove_path]\nMAX_SEQUENCE_LENGTH = 400\nMAX_FEATURES = 100000\nEMBEDDING_DIM = 300\ntorch.manual_seed(0)\ndataloader = DataLoader()\nembedding_index = dataloader.load_embedding(embedding_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:00:34.753981Z","iopub.execute_input":"2024-01-24T22:00:34.754321Z","iopub.status.idle":"2024-01-24T22:03:54.592050Z","shell.execute_reply.started":"2024-01-24T22:00:34.754294Z","shell.execute_reply":"2024-01-24T22:03:54.590886Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total 2195884 word vectors\n","output_type":"stream"}]},{"cell_type":"code","source":"train_x = pd.read_csv(os.path.join(dirname, 'cleaned_train_x.csv'))\nval_x = pd.read_csv(os.path.join(dirname, 'cleaned_val_x.csv'))\ntest_x = pd.read_csv(os.path.join(dirname, 'cleaned_test_x.csv'))","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:03:54.594116Z","iopub.execute_input":"2024-01-24T22:03:54.594496Z","iopub.status.idle":"2024-01-24T22:03:58.008005Z","shell.execute_reply.started":"2024-01-24T22:03:54.594461Z","shell.execute_reply":"2024-01-24T22:03:58.007210Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_y = pd.read_csv(os.path.join(dirname, 'train_y.csv'))\nval_y = pd.read_csv(os.path.join(dirname, 'val_y.csv'))\nlist_classes = ['y']\ntrain_y, val_y = dataloader.load_dataset(train_x, train_y, val_x, val_y, test_x, list_classes)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:03:58.009268Z","iopub.execute_input":"2024-01-24T22:03:58.009534Z","iopub.status.idle":"2024-01-24T22:03:58.593314Z","shell.execute_reply.started":"2024-01-24T22:03:58.009511Z","shell.execute_reply":"2024-01-24T22:03:58.592373Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Shape of train_y : (269038, 1)\nShape of val_y : (45180, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = MAX_FEATURES)\ntrain_x, test_x, val_x, word_index = dataloader.tokenize(tokenizer, MAX_SEQUENCE_LENGTH)\nembedding_matrix = dataloader.create_embedding_matrix(word_index, EMBEDDING_DIM, embedding_index, MAX_FEATURES)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:03:58.596294Z","iopub.execute_input":"2024-01-24T22:03:58.596908Z","iopub.status.idle":"2024-01-24T22:04:46.072266Z","shell.execute_reply.started":"2024-01-24T22:03:58.596871Z","shell.execute_reply":"2024-01-24T22:04:46.071365Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Shape of train_x tensor: (269038, 400)\nShape of test_data tensor: (133782, 400)\nShape of val_data tensor: (45180, 400)\nFound 136016 unique tokens\nNull word embeddings: 21362\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_x.shape)\nprint(train_y.shape)\nprint(val_x.shape)\nprint(val_y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:04:46.073478Z","iopub.execute_input":"2024-01-24T22:04:46.073757Z","iopub.status.idle":"2024-01-24T22:04:46.078881Z","shell.execute_reply.started":"2024-01-24T22:04:46.073733Z","shell.execute_reply":"2024-01-24T22:04:46.077972Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(269038, 400)\n(269038, 1)\n(45180, 400)\n(45180, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"MODEL_CHECKPOINT_FOLDER = \"checkpoints/\"\nTEMPORARY_CHECKPOINTS_PATH = 'temporary_checkpoints/'\nMAX_SENTENCE_LENGTH = 350\nnb_words = min(MAX_FEATURES, len(word_index))\ndef get_model():\n    return get_av_rnn(nb_words, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, out_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:04:46.080120Z","iopub.execute_input":"2024-01-24T22:04:46.080451Z","iopub.status.idle":"2024-01-24T22:04:46.091364Z","shell.execute_reply.started":"2024-01-24T22:04:46.080419Z","shell.execute_reply":"2024-01-24T22:04:46.090711Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_x = np.concatenate((train_x, val_x), axis = 0)\ntrain_y = np.concatenate((train_y, val_y), axis = 0)\nprint(train_x.shape)\nprint(train_y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:04:46.092539Z","iopub.execute_input":"2024-01-24T22:04:46.092832Z","iopub.status.idle":"2024-01-24T22:04:46.280634Z","shell.execute_reply.started":"2024-01-24T22:04:46.092807Z","shell.execute_reply":"2024-01-24T22:04:46.279633Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(314218, 400)\n(314218, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"def worst_group_accuracy(prediction, y):\n    \"\"\"\n        Compute the worst group accuracy, with the groups being defined by ['male', 'female', 'LGBTQ',\n        'christian', 'muslim', 'other_religions', 'black', 'white'] for positive and negative toxicity.\n        arguments:\n            prediction [pandas.DataFrame]: dataframe with 2 columns (index and pred)\n            y [pandas.DataFrame]: dataframe containing the metadata\n        returns:\n            wga [float]: worst group accuracy\n    \"\"\"\n    y.loc[prediction.index, 'pred'] = prediction.pred\n\n    categories = ['male', 'female', 'LGBTQ', 'christian', 'muslim', 'other_religions', 'black', 'white']\n    accuracies = []\n    for category in categories:\n        for label in [0, 1]:\n            group = y.loc[y[category] == label]\n            group_accuracy = (group['y'] == (group['pred'] > 0.5)).mean()\n            accuracies.append(group_accuracy)\n    \n    acc_index = 1\n    for cate in categories:\n        for label in [1]:\n            print(f'{cate}_{label}: {accuracies[acc_index]}')\n            acc_index += 2\n    wga = np.min(accuracies)\n    return wga","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:04:46.281973Z","iopub.execute_input":"2024-01-24T22:04:46.282349Z","iopub.status.idle":"2024-01-24T22:04:46.291103Z","shell.execute_reply.started":"2024-01-24T22:04:46.282322Z","shell.execute_reply":"2024-01-24T22:04:46.289979Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"###################################\n### with CV\n###################################\ntrainer = Trainer(model_stamp='av_rnn', epoch_num=6, learning_rate=1e-3)\n\nmodels,val_loss,total_auc,fold_predictions = trainer.train_folds(X=train_x, y=train_y, fold_count=3, batch_size=256, get_model_func=get_model)\nprint(\"Predicting val results...\")\nval_predicts_list = []\n\nfor fold_id, model in enumerate(models):\n    val_predicts = model.predict(val_x, batch_size=256, verbose=1)\n    val_predicts_list.append(val_predicts)\n\navg_val_predicts = np.zeros(val_predicts_list[0].shape)\nfor fold_predict in val_predicts_list:\n    avg_val_predicts += fold_predict\navg_val_predicts /= len(val_predicts_list)\n\nval_y_test = pd.read_csv(os.path.join(dirname, 'val_y.csv'))\npred_df = pd.DataFrame()\npred_df['pred'] = [val[-1] for val in avg_val_predicts]\npred_df = pred_df.reset_index()\nmetric = worst_group_accuracy(pred_df, val_y_test)\nprint(f'AVG_WGA: {metric}')","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:04:46.292386Z","iopub.execute_input":"2024-01-24T22:04:46.292741Z","iopub.status.idle":"2024-01-24T22:46:13.195427Z","shell.execute_reply.started":"2024-01-24T22:04:46.292709Z","shell.execute_reply":"2024-01-24T22:46:13.194262Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 400)]                0         []                            \n                                                                                                  \n embedding (Embedding)       (None, 400, 300)             3000000   ['input_1[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d (Spatial  (None, 400, 300)             0         ['embedding[0][0]']           \n Dropout1D)                                                                                       \n                                                                                                  \n bidirectional (Bidirection  (None, 400, 120)             130320    ['spatial_dropout1d[0][0]']   \n al)                                                                                              \n                                                                                                  \n bidirectional_1 (Bidirecti  (None, 400, 120)             65520     ['bidirectional[0][0]']       \n onal)                                                                                            \n                                                                                                  \n concatenate (Concatenate)   (None, 400, 240)             0         ['bidirectional[0][0]',       \n                                                                     'bidirectional_1[0][0]']     \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate[0][0]']         \n                                                                                                  \n global_max_pooling1d (Glob  (None, 240)                  0         ['concatenate[0][0]']         \n alMaxPooling1D)                                                                                  \n                                                                                                  \n global_average_pooling1d (  (None, 240)                  0         ['concatenate[0][0]']         \n GlobalAveragePooling1D)                                                                          \n                                                                                                  \n attention_weighted_average  (None, 240)                  240       ['concatenate[0][0]']         \n  (AttentionWeightedAverage                                                                       \n )                                                                                                \n                                                                                                  \n concatenate_1 (Concatenate  (None, 960)                  0         ['last[0][0]',                \n )                                                                   'global_max_pooling1d[0][0]',\n                                                                     'global_average_pooling1d[0][\n                                                                    0]',                          \n                                                                     'attention_weighted_average[0\n                                                                    ][0]']                        \n                                                                                                  \n dropout (Dropout)           (None, 960)                  0         ['concatenate_1[0][0]']       \n                                                                                                  \n dense (Dense)               (None, 144)                  138384    ['dropout[0][0]']             \n                                                                                                  \n dense_1 (Dense)             (None, 1)                    145       ['dense[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 30334609 (115.72 MB)\nTrainable params: 334609 (1.28 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/6\n819/819 [==============================] - 129s 148ms/step - loss: 0.2292 - accuracy: 0.9150 - val_loss: 0.2168 - val_accuracy: 0.9007\nEpoch 2/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.2018 - accuracy: 0.9204 - val_loss: 0.1968 - val_accuracy: 0.9147\nEpoch 3/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1929 - accuracy: 0.9221 - val_loss: 0.1905 - val_accuracy: 0.9219\nEpoch 4/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1875 - accuracy: 0.9238 - val_loss: 0.1912 - val_accuracy: 0.9152\nEpoch 5/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1828 - accuracy: 0.9248 - val_loss: 0.1825 - val_accuracy: 0.9237\nEpoch 6/6\n819/819 [==============================] - 123s 151ms/step - loss: 0.1783 - accuracy: 0.9267 - val_loss: 0.1790 - val_accuracy: 0.9246\n3274/3274 [==============================] - 69s 21ms/step\nAUC Score 0.962014290321151\nModel: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 400)]                0         []                            \n                                                                                                  \n embedding_1 (Embedding)     (None, 400, 300)             3000000   ['input_2[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_1 (Spati  (None, 400, 300)             0         ['embedding_1[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_2 (Bidirecti  (None, 400, 120)             130320    ['spatial_dropout1d_1[0][0]'] \n onal)                                                                                            \n                                                                                                  \n bidirectional_3 (Bidirecti  (None, 400, 120)             65520     ['bidirectional_2[0][0]']     \n onal)                                                                                            \n                                                                                                  \n concatenate_2 (Concatenate  (None, 400, 240)             0         ['bidirectional_2[0][0]',     \n )                                                                   'bidirectional_3[0][0]']     \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_2[0][0]']       \n                                                                                                  \n global_max_pooling1d_1 (Gl  (None, 240)                  0         ['concatenate_2[0][0]']       \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_1  (None, 240)                  0         ['concatenate_2[0][0]']       \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n attention_weighted_average  (None, 240)                  240       ['concatenate_2[0][0]']       \n _1 (AttentionWeightedAvera                                                                       \n ge)                                                                                              \n                                                                                                  \n concatenate_3 (Concatenate  (None, 960)                  0         ['last[0][0]',                \n )                                                                   'global_max_pooling1d_1[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_1[0\n                                                                    ][0]',                        \n                                                                     'attention_weighted_average_1\n                                                                    [0][0]']                      \n                                                                                                  \n dropout_1 (Dropout)         (None, 960)                  0         ['concatenate_3[0][0]']       \n                                                                                                  \n dense_2 (Dense)             (None, 144)                  138384    ['dropout_1[0][0]']           \n                                                                                                  \n dense_3 (Dense)             (None, 1)                    145       ['dense_2[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 30334609 (115.72 MB)\nTrainable params: 334609 (1.28 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/6\n819/819 [==============================] - 132s 152ms/step - loss: 0.2405 - accuracy: 0.9028 - val_loss: 0.1874 - val_accuracy: 0.9242\nEpoch 2/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.2047 - accuracy: 0.9152 - val_loss: 0.1840 - val_accuracy: 0.9233\nEpoch 3/6\n819/819 [==============================] - 123s 151ms/step - loss: 0.1947 - accuracy: 0.9193 - val_loss: 0.1816 - val_accuracy: 0.9250\nEpoch 4/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1886 - accuracy: 0.9215 - val_loss: 0.1828 - val_accuracy: 0.9255\nEpoch 5/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1837 - accuracy: 0.9245 - val_loss: 0.1817 - val_accuracy: 0.9240\nEpoch 6/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1784 - accuracy: 0.9259 - val_loss: 0.1766 - val_accuracy: 0.9268\n3274/3274 [==============================] - 69s 21ms/step\nAUC Score 0.9176293349262269\nModel: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_3 (InputLayer)        [(None, 400)]                0         []                            \n                                                                                                  \n embedding_2 (Embedding)     (None, 400, 300)             3000000   ['input_3[0][0]']             \n                                                          0                                       \n                                                                                                  \n spatial_dropout1d_2 (Spati  (None, 400, 300)             0         ['embedding_2[0][0]']         \n alDropout1D)                                                                                     \n                                                                                                  \n bidirectional_4 (Bidirecti  (None, 400, 120)             130320    ['spatial_dropout1d_2[0][0]'] \n onal)                                                                                            \n                                                                                                  \n bidirectional_5 (Bidirecti  (None, 400, 120)             65520     ['bidirectional_4[0][0]']     \n onal)                                                                                            \n                                                                                                  \n concatenate_4 (Concatenate  (None, 400, 240)             0         ['bidirectional_4[0][0]',     \n )                                                                   'bidirectional_5[0][0]']     \n                                                                                                  \n last (Lambda)               (None, 240)                  0         ['concatenate_4[0][0]']       \n                                                                                                  \n global_max_pooling1d_2 (Gl  (None, 240)                  0         ['concatenate_4[0][0]']       \n obalMaxPooling1D)                                                                                \n                                                                                                  \n global_average_pooling1d_2  (None, 240)                  0         ['concatenate_4[0][0]']       \n  (GlobalAveragePooling1D)                                                                        \n                                                                                                  \n attention_weighted_average  (None, 240)                  240       ['concatenate_4[0][0]']       \n _2 (AttentionWeightedAvera                                                                       \n ge)                                                                                              \n                                                                                                  \n concatenate_5 (Concatenate  (None, 960)                  0         ['last[0][0]',                \n )                                                                   'global_max_pooling1d_2[0][0]\n                                                                    ',                            \n                                                                     'global_average_pooling1d_2[0\n                                                                    ][0]',                        \n                                                                     'attention_weighted_average_2\n                                                                    [0][0]']                      \n                                                                                                  \n dropout_2 (Dropout)         (None, 960)                  0         ['concatenate_5[0][0]']       \n                                                                                                  \n dense_4 (Dense)             (None, 144)                  138384    ['dropout_2[0][0]']           \n                                                                                                  \n dense_5 (Dense)             (None, 1)                    145       ['dense_4[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 30334609 (115.72 MB)\nTrainable params: 334609 (1.28 MB)\nNon-trainable params: 30000000 (114.44 MB)\n__________________________________________________________________________________________________\nEpoch 1/6\n819/819 [==============================] - 131s 152ms/step - loss: 0.2310 - accuracy: 0.9060 - val_loss: 0.2048 - val_accuracy: 0.9173\nEpoch 2/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1971 - accuracy: 0.9178 - val_loss: 0.2271 - val_accuracy: 0.9053\nEpoch 3/6\n819/819 [==============================] - 123s 151ms/step - loss: 0.1869 - accuracy: 0.9215 - val_loss: 0.1920 - val_accuracy: 0.9217\nEpoch 4/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1798 - accuracy: 0.9245 - val_loss: 0.2092 - val_accuracy: 0.9112\nEpoch 5/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1741 - accuracy: 0.9259 - val_loss: 0.2070 - val_accuracy: 0.9135\nEpoch 6/6\n819/819 [==============================] - 123s 150ms/step - loss: 0.1693 - accuracy: 0.9287 - val_loss: 0.2059 - val_accuracy: 0.9102\n3274/3274 [==============================] - 69s 21ms/step\nAUC Score 0.9165197338778208\nPredicting val results...\n177/177 [==============================] - 8s 46ms/step\n177/177 [==============================] - 8s 46ms/step\n177/177 [==============================] - 8s 47ms/step\nmale_1: 0.9074501573976915\nfemale_1: 0.9117297572568325\nLGBTQ_1: 0.8263555250514756\nchristian_1: 0.9382417582417583\nmuslim_1: 0.843127962085308\nother_religions_1: 0.8681541582150102\nblack_1: 0.7893462469733656\nwhite_1: 0.8064178583885595\nAVG_WGA: 0.7893462469733656\n","output_type":"stream"}]},{"cell_type":"code","source":"for fold_id, model in enumerate(models):\n    val_predicts = model.predict(val_x, batch_size=256, verbose=1)\n    val_predicts_list.append(val_predicts)\n\navg_val_predicts = np.zeros(val_predicts_list[0].shape)\nfor fold_predict in val_predicts_list:\n    avg_val_predicts += fold_predict\navg_val_predicts /= len(val_predicts_list)\n\nval_y_test = pd.read_csv(os.path.join(dirname, 'val_y.csv'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for pred in val_predicts_list:\n    pred_df = pd.DataFrame()\n    pred_df['pred'] = [val[-1] for val in pred]\n    pred_df = pred_df.reset_index()\n    metric = worst_group_accuracy(pred_df, val_y_test)\n    print(f'WGA: {metric}')\n    print('----------------')","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:51:27.252740Z","iopub.execute_input":"2024-01-24T22:51:27.253458Z","iopub.status.idle":"2024-01-24T22:51:27.536734Z","shell.execute_reply.started":"2024-01-24T22:51:27.253423Z","shell.execute_reply":"2024-01-24T22:51:27.535652Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"male_1: 0.910598111227702\nfemale_1: 0.9149550161262944\nLGBTQ_1: 0.8311599176389842\nchristian_1: 0.9371428571428572\nmuslim_1: 0.8459715639810427\nother_religions_1: 0.8681541582150102\nblack_1: 0.7875302663438256\nwhite_1: 0.807464248343216\nWGA: 0.7875302663438256\n----------------\nmale_1: 0.9118572927597062\nfemale_1: 0.9164827703276184\nLGBTQ_1: 0.8277282086479066\nchristian_1: 0.9391208791208792\nmuslim_1: 0.8454976303317535\nother_religions_1: 0.8742393509127789\nblack_1: 0.801452784503632\nwhite_1: 0.8099058249040809\nWGA: 0.801452784503632\n----------------\nmale_1: 0.8906610703043022\nfemale_1: 0.8981497199117298\nLGBTQ_1: 0.8016472203157172\nchristian_1: 0.9296703296703297\nmuslim_1: 0.8241706161137441\nother_religions_1: 0.8519269776876268\nblack_1: 0.7524213075060533\nwhite_1: 0.7854900592954308\nWGA: 0.7524213075060533\n----------------\n","output_type":"stream"}]},{"cell_type":"code","source":"for pred in val_predicts_list:\n    pred_df = pd.DataFrame()\n    pred_df['pred'] = [val[-1] for val in pred]\n    pred_df['pred'] = [1 if x > 0.5 else 0 for x in pred_df['pred']]\n    pred_df = pred_df.reset_index()\n    metric = worst_group_accuracy(pred_df, val_y_test)\n    print(f'WGA: {metric}')\n    print('----------------')","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:56:26.020558Z","iopub.execute_input":"2024-01-24T22:56:26.021429Z","iopub.status.idle":"2024-01-24T22:56:26.397744Z","shell.execute_reply.started":"2024-01-24T22:56:26.021395Z","shell.execute_reply":"2024-01-24T22:56:26.396552Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"male_1: 0.910598111227702\nfemale_1: 0.9149550161262944\nLGBTQ_1: 0.8311599176389842\nchristian_1: 0.9371428571428572\nmuslim_1: 0.8459715639810427\nother_religions_1: 0.8681541582150102\nblack_1: 0.7875302663438256\nwhite_1: 0.807464248343216\nWGA: 0.7875302663438256\n----------------\nmale_1: 0.9118572927597062\nfemale_1: 0.9164827703276184\nLGBTQ_1: 0.8277282086479066\nchristian_1: 0.9391208791208792\nmuslim_1: 0.8454976303317535\nother_religions_1: 0.8742393509127789\nblack_1: 0.801452784503632\nwhite_1: 0.8099058249040809\nWGA: 0.801452784503632\n----------------\nmale_1: 0.8906610703043022\nfemale_1: 0.8981497199117298\nLGBTQ_1: 0.8016472203157172\nchristian_1: 0.9296703296703297\nmuslim_1: 0.8241706161137441\nother_religions_1: 0.8519269776876268\nblack_1: 0.7524213075060533\nwhite_1: 0.7854900592954308\nWGA: 0.7524213075060533\n----------------\n","output_type":"stream"}]},{"cell_type":"code","source":"test_predicts_list = []\nfor fold_id, model in enumerate(models):\n    test_predicts = model.predict(test_x, batch_size=256, verbose=1)\n    test_predicts_list.append(test_predicts)\navg_test_predicts = np.zeros(test_predicts_list[0].shape)\nfor fold_predict in test_predicts_list:\n    avg_test_predicts += fold_predict\navg_test_predicts /= len(test_predicts_list)\npred_df = pd.DataFrame()\npred_df['pred'] = [val[-1] for val in avg_test_predicts]\npred_df = pred_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T21:16:22.508499Z","iopub.execute_input":"2024-01-24T21:16:22.508896Z","iopub.status.idle":"2024-01-24T21:17:57.700478Z","shell.execute_reply.started":"2024-01-24T21:16:22.508866Z","shell.execute_reply":"2024-01-24T21:17:57.699701Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"523/523 [==============================] - 23s 45ms/step\n523/523 [==============================] - 23s 45ms/step\n523/523 [==============================] - 23s 44ms/step\n523/523 [==============================] - 23s 44ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pred_df.to_csv('GRU_prediction.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T21:18:15.158395Z","iopub.execute_input":"2024-01-24T21:18:15.158778Z","iopub.status.idle":"2024-01-24T21:18:15.663650Z","shell.execute_reply.started":"2024-01-24T21:18:15.158747Z","shell.execute_reply":"2024-01-24T21:18:15.662753Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =  models[1]\ntest_predicts = model.predict(test_x, batch_size=256, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:52:47.134368Z","iopub.execute_input":"2024-01-24T22:52:47.134790Z","iopub.status.idle":"2024-01-24T22:53:12.714735Z","shell.execute_reply.started":"2024-01-24T22:52:47.134757Z","shell.execute_reply":"2024-01-24T22:53:12.713762Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"523/523 [==============================] - 25s 48ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pred_df = pd.DataFrame()\npred_df['pred'] = [val[-1] for val in test_predicts]\npred_df = pred_df.reset_index()\npred_df = pred_df.rename(columns={'index': 'ID'})\npred_df.to_csv('GRU_prediction_best.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T22:53:50.822134Z","iopub.execute_input":"2024-01-24T22:53:50.822909Z","iopub.status.idle":"2024-01-24T22:53:51.407522Z","shell.execute_reply.started":"2024-01-24T22:53:50.822876Z","shell.execute_reply":"2024-01-24T22:53:51.406542Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}